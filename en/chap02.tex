\chapter{Data models and transformations}

This chapter talks about the way the format the data is received in (a relational database) and the differences between a relational and a graph model. In the following sections, we figure out how to effectively transform the relational data into a social network and what additional information does the transformed model tell us about the data (and how to get/calculate the information, again, effectively).  

\dots

\section{Relational vs. graph model}

A short theoretical section about the differences between the two different data models.

\dots

\section{Transformation}

A section about the details of the relational - graph transformation, the way the graph is stored (and reasons why - with respect to the operations we want to run on the data).

\dots

\section{Processing available data}

\subsection{Categorizing publications}

This section talks about analyzing the publication data using different NLP techniques and categorizing them into both predefined and inferred categories using classic algorithms (e.g. K-means and the alternatives) and ML approaches (Bayesian topic modelling using LDA).

This is a part of the data mining done on the data for enhancing the graph data model. As of now, the publication data is rather opaque with only the publication identificators, relations to people and text annotations in natural languages. Through the related people, there are also transitive relations to other publications, which most likely share the topic with the original publication. This is also taken as a benchmark data for the NLP-powered categorization tasks.

\subsubsection{Wordnet}

\subsubsection{Embedding with count-based techniques (TF-IDF, GloVe)}

\subsubsection{LLM based embeddings}

\subsection{Clustering the data}

\subsubsection{LDA topic modelling}

\subsubsection{K-means with other embeddings}

\section{Inferring missing data}

This section talks about the data inference for missing data. This is a problem mostly for the external authors (with little to no affiliation to CUNI) who can be often only identified by their name and academic titles. We try to come up with a better way of ``filling in the blanks'' - either by using some basic statistics or some data extracted from the social network itself.

\subsection{Infering identities from the social network}

Search for Jaroslav Peška yields the following results:
\begin{itemize}
    \item doc. PhDr. Jaroslav Peška Ph.D. - 77815713
    \item doc. PhDr. Jaroslav Peška Ph.D. - null
    \item Jaroslav Peška - null
    \item Doc. PhDr. Jaroslav Peška Ph.D. - null
    \item doc. PhDr. Jaroslav Peška PhD. - null
\end{itemize}

Another example is the search for Dmytro Yu Balakin, which yields the following results:

\begin{itemize}
    \item Dmytro Yu Balakin
    \item Dmytro Yu Batakin
    \item Dmytro Yu. Balakin.
\end{itemize}

It is clear that most of those are likely the same person, but the data is not consistent. The first one is the correct one, but the other ones are missing the academic titles and the ``doc.'' prefix. The ``PhD.'' suffix is also inconsistent - sometimes it is ``PhD.'', sometimes ``Ph.D.''. The ``doc.'' prefix is also sometimes missing.

...
...

While it might be tempting to solve this "online" by visually merging the entities in the application's visualization layer, this causes multiple issues. The obvious one are the performance implications 

\section{Analyzing the social network}

The first contact with the network, description of some basic properties, discovering the features of the data and trying to mine some non-obvious relations from the data.

\dots